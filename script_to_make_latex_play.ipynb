{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-hebrew-numbers in c:\\users\\aviezer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYaml in c:\\users\\aviezer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-hebrew-numbers) (6.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-hebrew-numbers\n",
    "# sys.path\n",
    "# sys.path.append(r'C:\\Users\\Aviezer\\.virtualenvs\\Shatz_Project-Y4ZvSTsa\\Lib\\site-packages')\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports various packages\n",
    "import json, urllib.request\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os, platform, subprocess, csv\n",
    "import math\n",
    "from hebrew_numbers import int_to_gematria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function pulls a text from Sefaria's github repo, given a string with the name of the text in the repo's format\n",
    "#this will presumably be replaced with pulling a text from a downloaded copy of the sefaria repo\n",
    "def pull_text(string_for_link):\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/\"+string_for_link+\".json\"\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        text_json = json.loads(url.read().decode())\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this generates a list of links between texts in sefaria\n",
    "#this is used to link comments in the gemara to gemara they're on\n",
    "def pull_links():\n",
    "    link_list = []#blank list to be filled in\n",
    "    for i in range(9):#this increments through all the github files that contain links\n",
    "        with open('links/links'+str(i)+'.csv', encoding=\"utf-8\") as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)#skips first row\n",
    "            for row in csv_reader:\n",
    "                if row[2] == \"commentary\":#only interested in commentaries\n",
    "                    link = []\n",
    "                    link.append(row[0])\n",
    "                    link.append(row[1])\n",
    "                    link_list.append(link)\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = pull_links()#generates the list of comment links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_comment(comment_str, links):#matches a comment with the gemara it's on\n",
    "    for link in links:#for every link in the list\n",
    "        #if the text is in the list, return the text it's linked to\n",
    "        if comment_str in link[0]:\n",
    "            return link[1]\n",
    "        elif comment_str in link[1]:\n",
    "            return link[0]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_json(masekhet):\n",
    "    #this gets the index json for a particular masekhet, which includes info about perakim.\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/schemas/\"+masekhet+\".json\"\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        index_json = json.loads(url.read().decode())\n",
    "    chaps = index_json[\"alts\"][\"Chapters\"][\"nodes\"]\n",
    "    return chaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_perek(name):\n",
    "    name = name.split(' ')\n",
    "    masekhet = name[0]\n",
    "    daf,line = name[1].split(\":\")\n",
    "    chapters = get_index_json(masekhet)\n",
    "    ref = masekhet+\" \"+daf\n",
    "    for chapter in chapters:\n",
    "        for page in chapter[\"refs\"]:\n",
    "            if \":\" not in page and page==ref:\n",
    "                return chapter[\"title\"],chapter['heTitle']\n",
    "            elif \":\" in page and ref in page:\n",
    "                sections = page.split(\":\")[1]\n",
    "                sections = sections.split(\"-\")\n",
    "                if int(sections[0])<=int(line)<=int(sections[1]):\n",
    "                    return chapter[\"title\"],chapter['heTitle']\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_chapters(text_json, links):\n",
    "    #adds perek breaks to text json\n",
    "    refs = []\n",
    "    text_json[\"text_perakim\"] = []#original text, but with perakim breaks noted\n",
    "    text_json[\"chap_list\"] = []#list of chapter titles\n",
    "    daf_i = 1#initializing counters.\n",
    "    #Sefaria puts a blank spot for daf 1, so it starts with 1 not 2.\n",
    "    title = text_json[\"title\"]\n",
    "    current_perek = \"\"\n",
    "    j=0\n",
    "    for daf in text_json[\"text\"]:\n",
    "        if daf != []:#if daf isn't empty\n",
    "            comment_i = 1#comment counter\n",
    "            for comment in daf:\n",
    "                daf_num = math.floor(daf_i)#rounds daf down from 0.5 to get real number\n",
    "                if daf_num == daf_i:\n",
    "                    amud = \"a\"\n",
    "                else:\n",
    "                    amud = \"b\"#for daf with 0.5, it's daf X amud b\n",
    "                daf_ref = str(daf_num)+amud #makes davening number, like 4b\n",
    "                new_ref = title +\" \"+ daf_ref + \":\"+str(comment_i)\n",
    "                #adds masekhet name to daf reference\n",
    "                gemara_ref = \"\"\n",
    "                for link in links:#for every link in link list\n",
    "                    if link[0] == new_ref:#if the link is do the relevant daf\n",
    "                        gemara_ref = link[1]\n",
    "                        break\n",
    "                if \"-\" in gemara_ref:#if a reference spans a daf\n",
    "                    gemara_ref = gemara_ref.split(\"-\")[0]#returns the first part\n",
    "                if gemara_ref != \"\":\n",
    "                    ref_perek = find_perek(gemara_ref)#looks up the perek of the daf of gemara\n",
    "                    if ref_perek != current_perek:#if the reference is a new perek\n",
    "                        current_perek = ref_perek#set current perek\n",
    "                        perek_info = {\"name_en\":ref_perek[0],\"name_he\":ref_perek[1]}\n",
    "                        text_json[\"text\"][j].insert(comment_i-1,perek_info)\n",
    "                        #the above adds a dict with info on the perek into the text json\n",
    "                comment_i += 1\n",
    "        daf_i += 0.5\n",
    "        j += 1\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_body(hebrew_text, english_text, settings):\n",
    "    output = []\n",
    "    chap_num = 1\n",
    "    mishna_num = 1# lav davka mishna, just the smaller divisions of the text\n",
    "    title = hebrew_text[\"heTitle\"]\n",
    "    title_command = r\"\\newcommand{\\texttitle}{\"+title+\"}\"#sets title\n",
    "    divisions_en = hebrew_text[\"sectionNames\"] #gets names of the sections for the specific text\n",
    "    divisions_he = []\n",
    "    #the following uses the CSV of section names to get the Hebrew sections names\n",
    "    with open('resources/section_names.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            for division in divisions_en:\n",
    "                if row[0] == division:\n",
    "                    divisions_he.append(row[1])\n",
    "    if \"Daf\" in divisions_en:\n",
    "        #if the text is based on dappim, run the script to add perakim notations\n",
    "        hebrew_text = match_chapters(hebrew_text,link_list)       \n",
    "    for perek in hebrew_text[\"text\"]:\n",
    "        if any(perek):\n",
    "            if type(perek[0]) == dict and \"name_he\" in perek[0].keys():\n",
    "                #if there's a new perek dict note, add the LaTeX code for the new perek\n",
    "                output.append(r\"\\newchap{\"+parse_perek_title(perek[0])+\"}\")\n",
    "            if \"Daf\" in divisions_en:\n",
    "                #this adds daf numbers for each new daf, ignoring the amud break\n",
    "                daf = ((chap_num+1)/2)\n",
    "                if daf == round(daf):\n",
    "                    daftitle = int_to_gematria(round(daf), gershayim=False)\n",
    "                    output.append(r\"\\newsection{דף \"+daftitle+\"}\")              \n",
    "            else:\n",
    "                output.append(r\"\\newsection{\"+divisions_he[0]+int_to_gematria(chap_num, gershayim=False)+\"}\")\n",
    "            for par in perek:\n",
    "                #prints next block of text\n",
    "                textblock = \"\"\n",
    "                if type(par) == dict and \"name_he\" in par.keys() and par[\"name_en\"] != \"Chapter 1\":\n",
    "                    if textblock != \"\":\n",
    "                        new_text = make_section(textblock,None, settings, chap_num, mishna_num)\n",
    "                        output.append(new_text)\n",
    "                else:\n",
    "                    while type(par)==list:\n",
    "                        new_par = \"\"\n",
    "                        for item in par:\n",
    "                            new_par += item\n",
    "                        par = new_par\n",
    "                    if type(par) != dict:\n",
    "                        textblock += par\n",
    "                mishna_num += 1\n",
    "            new_text = make_section(textblock,None, settings, chap_num, mishna_num)\n",
    "            if \"twocol\" in new_text and \"twocol\" in output[-1]:\n",
    "                new_text = new_text.replace(r\"\\twocol{\",\"\\par \")\n",
    "                output = output[0:-1]+[output[-1][0:-1]]+[new_text]\n",
    "            else:\n",
    "                output.append(new_text)\n",
    "        chap_num += 1\n",
    "        mishna_num = 1\n",
    "    return title_command, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_perek_title(perekDict):\n",
    "    chap_num = perekDict[\"name_en\"].replace(\"Chapter \",\"\")\n",
    "    title = r\"פרק \\hebrewnumeral{\"+chap_num+r\"}\\quad \"+perekDict[\"name_he\"]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeformatting(text):\n",
    "    while \"<\" in text and \">\" in text:\n",
    "        loc1 = text.find(\"<\")\n",
    "        loc2 = text.find(\">\",loc1)+1\n",
    "        text = text.replace(text[loc1:loc2],\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_section(hebrew_text, english, settings, chap_num, mishna_num):\n",
    "    #turns a block of text into a latex section using the \\textblock or \\twocol command\n",
    "    if english != \"\" and english != None:\n",
    "        english = english.replace(\"[\",\"{[\")\n",
    "        english = english.replace(\"]\",\"]}\")\n",
    "        output = r\"\\textblock{\"+hebrew_text+\"}{\"+english+\"}\"\n",
    "    elif settings[\"layout\"] == \"twocol\":\n",
    "        output= r\"\\twocol{\"+hebrew_text+\"}\"\n",
    "    else:\n",
    "        output= r\"\\textblock{\"+hebrew_text+\"}\"\n",
    "    with open('resources/html_tags_to_tex.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[0] in output:\n",
    "                output = output.replace(row[0],row[1])\n",
    "    output = removeformatting(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_format(template_lines,settings):\n",
    "    output = []\n",
    "    #this sets the format for the text in the LaTeX preamble.\n",
    "    #ths line[0:-1] is the text of the line in LaTeX being converted by the script.\n",
    "    #the -1 is needed to exclude the \\n for line break at the end of each line.\n",
    "    #these work by converting a LaTeX comment for a specific formatting piece to a command, based on what's in the settings json.\n",
    "    for line in template_lines:\n",
    "        if line[0:-1] in settings.keys():\n",
    "            setting_output = line[0:-1] + \"=\"+settings[line[0:-1]]+\",\\n\"\n",
    "            output.append(setting_output)\n",
    "        elif line[0:-1] == \"%setfontsize\":\n",
    "            fontsize = settings[\"fontsize\"]\n",
    "            skip = fontsize * settings[\"spacing\"]\n",
    "            fontsizestr = r\"\\fontsize{\"+str(fontsize)+r\"pt}{\"+str(round(skip,1))+r\"pt} \\selectfont\"\n",
    "            output.append(fontsizestr)\n",
    "        elif line[0:-1] == \"%sethebfont\":\n",
    "            if settings[\"hebboldfont\"] == \"\":\n",
    "                font = r\"\\setmainfont{\"+settings[\"hebfont\"]+r\"}\"\n",
    "            else:\n",
    "                font = r\"\\setmainfont[BoldFont = {\"+settings[\"hebboldfont\"]+r'}]{'+settings[\"hebfont\"]+r\"}\"\n",
    "            output.append(font)\n",
    "        elif line[0:-1] == \"%setengfont\" and settings[\"engfont\"] != 0:\n",
    "            engfont = r'\\newfontfamily\\englishfont{'+settings[\"engfont\"]+r'}'\n",
    "            output.append(engfont)\n",
    "        elif line[0:-1] == \"%setparskip\" and settings[\"parskip\"] != 0:\n",
    "            parskip = r'\\setlength{\\parskip}{'+settings[\"parskip\"]+'}'\n",
    "            output.append(parskip)\n",
    "        elif line[0:-1] == \"%pagenumber\":\n",
    "            if settings[\"pagenumloc\"] == \"topouter\":\n",
    "                pagenum = r\"\\fancyhead[LO,RE]{num}\"\n",
    "            elif settings[\"pagenumloc\"] == \"bottommiddle\":\n",
    "                pagenum = r\"\\fancyfoot[C]{num}\"\n",
    "            if settings[\"pagenumheb\"] == True:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\hebrewnumeral{\\thepage}\")\n",
    "            else:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\thepage\")\n",
    "            output.append(pagenum)\n",
    "        elif line[0:-1] == \"%header\":\n",
    "            if settings[\"headpos\"] == \"center\":\n",
    "                odd_header = r\"\\fancyhead[CO]{\"\n",
    "                even_header = r\"\\fancyhead[CE]{\"\n",
    "            elif settings[\"headpos\"] == \"inner\":\n",
    "                odd_header = r\"\\fancyhead[RO]{\"\n",
    "                even_header = r\"\\fancyhead[LE]{\"\n",
    "            if settings[\"evenhead\"] == \"title\":\n",
    "                even_header += r\"\\texttitle\"\n",
    "            elif settings[\"evenhead\"] == \"chapter\":\n",
    "                even_header += r\"\\chapname\"\n",
    "            elif settings[\"evenhead\"] == \"titlechapter\":\n",
    "                even_header += r\"\\texttitle \\space\\textendash\\space \\chapname\"\n",
    "            if settings[\"oddhead\"] == \"title\":\n",
    "                odd_header += r\"\\texttitle\"\n",
    "            elif settings[\"oddhead\"] == \"chapter\":\n",
    "                odd_header += r\"\\chapname\"\n",
    "            elif settings[\"oddhead\"] == \"titlechapter\":\n",
    "                odd_header += r\"\\texttitle \\space\\textendash\\space \\chapname\"\n",
    "            odd_header += \"}\"\n",
    "            even_header += \"}\"\n",
    "            output.append(odd_header)\n",
    "            output.append(even_header)\n",
    "        elif line[0:-1] == \"%chapfontsize\":\n",
    "            if \"chapfontsize\" in settings.keys():\n",
    "                headerfontcommand = r\"\\fontsize{\"+settings[\"chapfontsize\"]+\"}{\"+settings[\"chapfontsize\"]+r\"}\\selectfont\"\n",
    "            else:\n",
    "                headerfontcommand = r\"\\LARGE\"\n",
    "            output.append(headerfontcommand)\n",
    "        else:\n",
    "            output.append(line)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bib_info(json):\n",
    "    #puts bibliographic info in a dict\n",
    "    source_data = {}\n",
    "    source_data[\"source\"] = json[\"versionSource\"]\n",
    "    source_data[\"license\"] = json[\"license\"]\n",
    "    source_data[\"version\"] = json[\"versionTitle\"]\n",
    "    return source_data\n",
    "\n",
    "def print_source_data(source_list):\n",
    "    output = []\n",
    "    output.append(r\"\\begin{itemize}\")\n",
    "    #puts every piece of bibliographic info into a copyright notice\n",
    "    for source in source_list:\n",
    "        if \"NC\" in source[\"license\"] or \"Copyright\" in source[\"license\"]:\n",
    "            return [\"NC\",source[\"version\"]]\n",
    "        versiontitle = source[\"version\"].replace(\"-\",r\"\\textendash \")\n",
    "        output.append(r\"\\item \"+versiontitle)\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\begin{itemize}\")\n",
    "        output.append(r\"\\item License: \"+source[\"license\"])\n",
    "        output.append(r\"\\item Source: \\url{\"+source[\"source\"]+\"}\")\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\end{itemize}\")\n",
    "    output.append(r\"\\end{itemize}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads template file\n",
    "inputpath = os.path.join(\"resources\",\"input.tex\")\n",
    "def pullinput(inputpath):\n",
    "    with open(inputpath, 'r', encoding='utf-8') as infile:\n",
    "        template_lines = list(infile.readlines())\n",
    "    return template_lines\n",
    "\n",
    "#converts input into output\n",
    "def writeoutput(outputpath, template, formatting):\n",
    "    sources = []\n",
    "    template_with_settings = set_format(template,formatting)#reads settings\n",
    "    sefaria_json = pull_text(formatting[\"text\"])#pulls json from Sefaria\n",
    "    sources.append(get_bib_info(sefaria_json))#puts bibliographic info in sources list\n",
    "    if formatting[\"translation\"]!= \"\":\n",
    "        #pulls translation, if any, and adds to bibliographic list\n",
    "        english_json = pull_text(formatting[\"translation\"])\n",
    "        sources.append(get_bib_info(english_json))\n",
    "        sefaria_result = make_body(sefaria_json,english_json,formatting)\n",
    "    else:\n",
    "        sefaria_result = make_body(sefaria_json, None, formatting)\n",
    "    body = sefaria_result[1]\n",
    "    title_command = sefaria_result[0]\n",
    "    source_listing = print_source_data(sources)\n",
    "    if source_listing[0] == \"NC\":#stops the script if the license doesn't allow the text to run\n",
    "        print(source_listing[1] + \" has a license which does not allow creation of this text.\")\n",
    "        return\n",
    "    with open(outputpath, 'w', encoding='utf-8') as outfile:\n",
    "        for line in template_with_settings:\n",
    "            if line == \"%title_here\\n\":\n",
    "                outfile.write(title_command)\n",
    "            elif line == \"%license info\\n\":\n",
    "                for item in source_listing:\n",
    "                    outfile.write(item)\n",
    "                    outfile.write(\"\\n\")\n",
    "            elif line == \"%body_here\\n\":\n",
    "                for newline in body:\n",
    "                    outfile.write(newline)\n",
    "                    outfile.write(\"\\n\")\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "                if \"\\n\" not in line:\n",
    "                    outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfrw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Coding\\Shatz Project\\books-from-sefaria\\script_to_make_latex.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/Shatz%20Project/books-from-sefaria/script_to_make_latex.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39m#all this is doing is flipping \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Coding/Shatz%20Project/books-from-sefaria/script_to_make_latex.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpdfrw\u001b[39;00m \u001b[39mimport\u001b[39;00m PdfReader, PdfWriter\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/Shatz%20Project/books-from-sefaria/script_to_make_latex.ipynb#ch0000016?line=2'>3</a>\u001b[0m \u001b[39m#flips PDF for print on demand\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/Shatz%20Project/books-from-sefaria/script_to_make_latex.ipynb#ch0000016?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflip_PDF\u001b[39m(inpfn):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfrw'"
     ]
    }
   ],
   "source": [
    "#all this is doing is flipping \n",
    "from pdfrw import PdfReader, PdfWriter\n",
    "#flips PDF for print on demand\n",
    "def flip_PDF(inpfn):\n",
    "    rotate = 180\n",
    "\n",
    "    #ranges = [[int(y) for y in x.split('-')] for x in ranges]\n",
    "    outname = inpfn.split(\".pdf\")\n",
    "    outfn = outname[0]+\".rotated.\"+outname[1]+\"pdf\"\n",
    "    print(outfn)\n",
    "    #outfn = 'rotate.%s' % os.path.basename(inpfn)\n",
    "    trailer = PdfReader(inpfn)\n",
    "    pages = trailer.pages\n",
    "\n",
    "    ranges = [[1, len(pages)]]\n",
    "\n",
    "    for onerange in ranges:\n",
    "        onerange = (onerange + onerange[-1:])[:2]\n",
    "        for pagenum in range(onerange[0]-1, onerange[1]):\n",
    "            pages[pagenum].Rotate = (int(pages[pagenum].inheritable.Rotate or\n",
    "                                         0) + rotate) % 360\n",
    "\n",
    "    outdata = PdfWriter(outfn)\n",
    "    outdata.trailer = trailer\n",
    "    outdata.write()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template_lines = pullinput(inputpath)\n",
    "# for line in template_lines:\n",
    "#     print(line)\n",
    "outputname = \"output.tex\"\n",
    "with open('book_settings.json',encoding='utf=8') as json_file:\n",
    "    book_settings = json.load(json_file)\n",
    "writeoutput(outputname,template_lines,book_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Coding\\Shatz Project\\books-from-sefaria\\script_to_make_latex.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Coding/Shatz%20Project/books-from-sefaria/script_to_make_latex.ipynb#ch0000018?line=0'>1</a>\u001b[0m subprocess\u001b[39m.\u001b[39;49mrun([\u001b[39m'\u001b[39;49m\u001b[39mxelatex\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m-interaction=nonstopmode\u001b[39;49m\u001b[39m'\u001b[39;49m, outputname])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/Shatz%20Project/books-from-sefaria/script_to_make_latex.ipynb#ch0000018?line=1'>2</a>\u001b[0m subprocess\u001b[39m.\u001b[39mrun([\u001b[39m'\u001b[39m\u001b[39mxelatex\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-interaction=nonstopmode\u001b[39m\u001b[39m'\u001b[39m, outputname])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/Shatz%20Project/books-from-sefaria/script_to_make_latex.ipynb#ch0000018?line=2'>3</a>\u001b[0m outputname \u001b[39m=\u001b[39m outputname\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.tex\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aviezer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:501\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    499\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 501\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    502\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\Aviezer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    963\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    964\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 966\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    967\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    968\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    969\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    970\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    971\u001b[0m                         errread, errwrite,\n\u001b[0;32m    972\u001b[0m                         restore_signals,\n\u001b[0;32m    973\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    974\u001b[0m                         start_new_session)\n\u001b[0;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    976\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\Aviezer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1435\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1435\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1436\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1437\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1438\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1439\u001b[0m                              creationflags,\n\u001b[0;32m   1440\u001b[0m                              env,\n\u001b[0;32m   1441\u001b[0m                              cwd,\n\u001b[0;32m   1442\u001b[0m                              startupinfo)\n\u001b[0;32m   1443\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1444\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1448\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1451\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1452\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "subprocess.run(['xelatex', '-interaction=nonstopmode', outputname])\n",
    "subprocess.run(['xelatex', '-interaction=nonstopmode', outputname])\n",
    "outputname = outputname.replace(\".tex\",\".pdf\")\n",
    "flip_PDF(outputname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b8770fc5ea69306154f127209e15264e283744e665fbe8b9f515bed02a48457"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
